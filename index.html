<!doctype html>
<!-- The Time Machine GitHub pages theme was designed and developed by Jon Rohan, on Feb 7, 2012. -->
<!-- Follow him for fun. http://twitter.com/jonrohan. Tail his code on https://github.com/jonrohan -->
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <link rel="stylesheet" href="stylesheets/stylesheet.css" media="screen">
  <link rel="stylesheet" href="stylesheets/github-dark.css">
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
  <script type="text/javascript" src="javascripts/script.js"></script>

  <title>Awesome-rl</title>
  <meta name="description" content="Reinforcement learning resources curated">

  <meta name="viewport" content="width=device-width,initial-scale=1">

</head>

<body>

  <div class="wrapper">
    <header>
      <h1 class="title">Awesome-rl</h1>
    </header>
    <div id="container">
      <p class="tagline">Reinforcement learning resources curated</p>
      <div id="main" role="main">
        <div class="download-bar">
        <div class="inner">
          <a href="https://github.com/aikorea/awesome-rl/tarball/master" class="download-button tar"><span>Download</span></a>
          <a href="https://github.com/aikorea/awesome-rl/zipball/master" class="download-button zip"><span>Download</span></a>
          <a href="https://github.com/aikorea/awesome-rl" class="code">View Awesome-rl on GitHub</a>
        </div>
        <span class="blc"></span><span class="trc"></span>
        </div>
        <article class="markdown-body">
          <h1>
<a id="awesome-reinforcement-learning" class="anchor" href="#awesome-reinforcement-learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Awesome Reinforcement Learning</h1>

<p>A curated list of resources dedicated to reinforcement learning.</p>

<p>We have pages for other topics: <a href="http://jiwonkim.org/awesome-rnn">awesome-rnn</a>, <a href="http://jiwonkim.org/awesome-deep-vision/">awesome-deep-vision</a>, <a href="http://jiwonkim.org/awesome-random-forest/">awesome-random-forest</a></p>

<h2>
<a id="contributing" class="anchor" href="#contributing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contributing</h2>

<p>Please feel free to <a href="https://github.com/aikorea/awesome-rl/pulls">pull requests</a></p>

<h2>
<a id="table-of-contents" class="anchor" href="#table-of-contents" aria-hidden="true"><span class="octicon octicon-link"></span></a>Table of Contents</h2>

<ul>
<li><a href="#codes">Codes</a></li>
<li>
<a href="#theory">Theory</a>

<ul>
<li><a href="#lectures">Lectures</a></li>
<li><a href="#books">Books</a></li>
<li><a href="#surveys">Surveys</a></li>
<li><a href="#papers--thesis">Papers / Thesis</a></li>
</ul>
</li>
<li>
<a href="#applications">Applications</a>

<ul>
<li><a href="#game-playing">Game Playing</a></li>
<li><a href="#robotics">Robotics</a></li>
<li><a href="#control">Control</a></li>
<li><a href="#operations-research">Operations Research</a></li>
<li><a href="#human-computer-interaction">Human Computer Interaction</a></li>
</ul>
</li>
<li><a href="#tutorials--websites">Tutorials / Websites</a></li>
<li><a href="#online-demos">Online Demos</a></li>
</ul>

<h2>
<a id="codes" class="anchor" href="#codes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Codes</h2>

<ul>
<li>Codes for examples and exercises in Richard Sutton and Andrew Barto's Reinforcement Learning: An Introduction

<ul>
<li><a href="http://waxworksmath.com/Authors/N_Z/Sutton/sutton.html">MATLAB Code</a></li>
<li>
<a href="https://webdocs.cs.ualberta.ca/%7Esutton/book/code/code.html">C/Lisp Code</a> </li>
<li>
<a href="http://webdocs.cs.ualberta.ca/%7Esutton/book/ebook/the-book.html">Book</a> </li>
</ul>
</li>
<li>Simulation code for Reinforcement Learning Control Problems

<ul>
<li><a href="http://pages.cs.wisc.edu/%7Efinton/poledriver.html">Pole-Cart Problem</a></li>
<li><a href="http://pages.cs.wisc.edu/%7Efinton/qcontroller.html">Q-learning Controller</a></li>
</ul>
</li>
<li><a href="http://www.cs.colostate.edu/%7Eanderson/res/rl/matlabpaper/rl.html">MATLAB Environment and GUI for Reinforcement Learning</a></li>
<li><a href="http://www-anw.cs.umass.edu/rlr/">Reinforcement Learning Repository - University of Massachusetts, Amherst</a></li>
<li><a href="http://burlap.cs.brown.edu/">Brown-UMBC Reinforcement Learning and Planning Library (Java)</a></li>
<li>
<a href="http://www.statsblogs.com/2014/01/07/reinforcement-learning-in-r-markov-decision-process-mdp-and-value-iteration/">Reinforcement Learning in R (MDP, Value Iteration)</a> </li>
<li><a href="https://jamh-web.appspot.com/download.htm">Reinforcement Learning Environment in Python and MATLAB</a></li>
<li>
<a href="http://glue.rl-community.org/wiki/Main_Page">RL-Glue</a> (standard interface for RL) and <a href="http://library.rl-community.org/wiki/Main_Page">RL-Glue Library</a>
</li>
<li>
<a href="http://www.pybrain.org/">PyBrain Library</a> - Python-Based Reinforcement learning, Artificial intelligence, and Neural network</li>
<li>
<a href="http://mmlf.sourceforge.net/">Maja</a> - Machine learning framework for problems in Reinforcement Learning in python</li>
<li>
<a href="http://servicerobotik.hs-weingarten.de/en/teachingbox.php">TeachingBox</a> - Java based Reinforcement Learning framework</li>
<li><a href="http://webdocs.cs.ualberta.ca/%7Evanhasse/code.html">Implementation of RL algorithms in Python/C++</a></li>
<li><a href="http://www.ias.informatik.tu-darmstadt.de/Research/PolicyGradientToolbox">Policy Gradient Reinforcement Learning Toolbox for MATLAB</a></li>
<li>
<a href="http://sourceforge.net/projects/piqle/">PIQLE</a> - Platform Implementing Q-LEarning and other RL algorithms</li>
</ul>

<h2>
<a id="theory" class="anchor" href="#theory" aria-hidden="true"><span class="octicon octicon-link"></span></a>Theory</h2>

<h3>
<a id="lectures" class="anchor" href="#lectures" aria-hidden="true"><span class="octicon octicon-link"></span></a>Lectures</h3>

<ul>
<li>[UCL] <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">COMPM050/COMPGI13 Reinforcement Learning</a> by David Silver</li>
<li>[UC Berkeley] CS188 Artificial Intelligence by Pieter Abbeel

<ul>
<li><a href="https://www.youtube.com/watch?v=i0o-ui1N35U">Lecture 8: Markov Decision Processes 1</a></li>
<li><a href="https://www.youtube.com/watch?v=Csiiv6WGzKM">Lecture 9: Markov Decision Processes 2</a></li>
<li><a href="https://www.youtube.com/watch?v=ifma8G7LegE">Lecture 10: Reinforcement Learning 1</a></li>
<li><a href="https://www.youtube.com/watch?v=Si1_YTw960c">Lecture 11: Reinforcement Learning 2</a></li>
</ul>
</li>
<li>[Udacity (Georgia Tech.)] <a href="https://www.udacity.com/course/machine-learning-reinforcement-learning--ud820">Machine Learning 3: Reinforcement Learning (CS7641)</a>
</li>
<li>[Stanford] <a href="https://www.youtube.com/watch?v=RtxI449ZjSc&amp;feature=relmfu">CS229 Machine Learning - Lecture 16: Reinforcement Learning</a> by Andrew Ng</li>
</ul>

<h3>
<a id="books" class="anchor" href="#books" aria-hidden="true"><span class="octicon octicon-link"></span></a>Books</h3>

<ul>
<li>Richard Sutton and Andrew Barto, Reinforcement Learning: An Introduction <a href="http://webdocs.cs.ualberta.ca/%7Esutton/book/ebook/the-book.html">[Book]</a> <a href="https://webdocs.cs.ualberta.ca/%7Esutton/book/code/code.html">[Code]</a>
</li>
<li>Csaba Szepesvari, Algorithms for Reinforcement Learning <a href="http://www.ualberta.ca/%7Eszepesva/papers/RLAlgsInMDPs.pdf">[Book]</a>
</li>
<li>David Poole and Alan Mackworth, Artificial Intelligence: Foundations of Computational Agents <a href="http://artint.info/html/ArtInt_262.html">[Book Chapter]</a>
</li>
<li>Dimitri P. Bertsekas and John N. Tsitsiklis, Neuro-Dynamic Programming <a href="http://www.amazon.com/Neuro-Dynamic-Programming-Optimization-Neural-Computation/dp/1886529108/ref=sr_1_3?s=books&amp;ie=UTF8&amp;qid=1442461075&amp;sr=1-3&amp;refinements=p_27%3AJohn+N.+Tsitsiklis+Dimitri+P.+Bertsekas">[Book (Amazon)]</a> <a href="http://www.mit.edu/%7Edimitrib/NDP_Encycl.pdf">[Summary]</a>
</li>
<li>Mykel J. Kochenderfer, Decision Making Under Uncertainty: Theory and Application <a href="http://www.amazon.com/Decision-Making-Under-Uncertainty-Application/dp/0262029251/ref=sr_1_1?ie=UTF8&amp;qid=1441126550&amp;sr=8-1&amp;keywords=kochenderfer&amp;pebp=1441126551594&amp;perid=1Y6RG2EGRD26659CJHH9">[Book (Amazon)]</a>
</li>
</ul>

<h3>
<a id="surveys" class="anchor" href="#surveys" aria-hidden="true"><span class="octicon octicon-link"></span></a>Surveys</h3>

<ul>
<li>Leslie Pack Kaelbling, Michael L. Littman, Andrew W. Moore, Reinforcement Learning: A Survey, JAIR, 1996. <a href="https://www.jair.org/media/301/live-301-1562-jair.pdf">[Paper]</a> </li>
<li>S. S. Keerthi and B. Ravindran, A Tutorial Survey of Reinforcement Learning, Sadhana, 1994. <a href="http://www.cse.iitm.ac.in/%7Eravi/papers/keerthi.rl-survey.pdf">[Paper]</a>
</li>
<li>Jens Kober, J. Andrew Bagnell, Jan Peters, Reinforcement Learning in Robotics, A Survey, IJRR, 2013. <a href="http://www.ias.tu-darmstadt.de/uploads/Publications/Kober_IJRR_2013.pdf">[Paper]</a>
</li>
<li>Littman, Michael L. "Reinforcement learning improves behaviour from evaluative feedback." Nature 521.7553 (2015): 445-451. <a href="http://www.nature.com/nature/journal/v521/n7553/full/nature14540.html">[Paper]</a>
</li>
<li>Marc P. Deisenroth, Gerhard Neumann, Jan Peter, A Survey on Policy Search for Robotics, Foundations and Trends in Robotics, 2014. <a href="https://spiral.imperial.ac.uk:8443/bitstream/10044/1/12051/7/fnt_corrected_2014-8-22.pdf">[Book]</a>
</li>
</ul>

<h3>
<a id="papers--thesis" class="anchor" href="#papers--thesis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Papers / Thesis</h3>

<ul>
<li>
<p>Foundational Papers</p>

<ul>
<li>Marvin Minsky, Steps toward Artificial Intelligence, Proceedings of the IRE, 1961. <a href="http://staffweb.worc.ac.uk/DrC/Courses%202010-11/Comp%203104/Tutor%20Inputs/Session%209%20Prep/Reading%20material/Minsky60steps.pdf">[Paper]</a>

<ul>
<li>discusses issues in RL such as the "credit assignment problem"</li>
</ul>
</li>
<li>Ian H. Witten, An Adaptive Optimal Controller for Discrete-Time Markov Environments, Information and Control, 1977. <a href="http://www.cs.waikato.ac.nz/%7Eihw/papers/77-IHW-AdaptiveController.pdf">[Paper]</a>

<ul>
<li>earliest publication on temporal-difference (TD) learning rule. </li>
</ul>
</li>
</ul>
</li>
<li>
<p>Solution Methods</p>

<ul>
<li>Dynamic Programming (DP):

<ul>
<li>Christopher J. C. H. Watkins, Learning from Delayed Rewards, Ph.D. Thesis, Cambridge University, 1989. <a href="https://www.cs.rhul.ac.uk/home/chrisw/new_thesis.pdf">[Thesis]</a>
</li>
</ul>
</li>
<li>Monte Carlo: 

<ul>
<li>Andrew Barto, Michael Duff, Monte Carlo Inversion and Reinforcement Learning, NIPS, 1994. <a href="http://papers.nips.cc/paper/865-monte-carlo-matrix-inversion-and-reinforcement-learning.pdf">[Paper]</a>
</li>
<li>Satinder P. Singh, Richard S. Sutton, Reinforcement Learning with Replacing Eligibility Traces, Machine Learning, 1996. <a href="http://www-all.cs.umass.edu/pubs/1995_96/singh_s_ML96.pdf">[Paper]</a>
</li>
</ul>
</li>
<li>Temporal-Difference: 

<ul>
<li>Richard S. Sutton, Learning to predict by the methods of temporal differences. Machine Learning 3: 9-44, 1988. <a href="http://webdocs.cs.ualberta.ca/%7Esutton/papers/sutton-88-with-erratum.pdf">[Paper]</a>
</li>
</ul>
</li>
<li>Q-Learning (Off-policy TD algorithm):

<ul>
<li>Chris Watkins, Learning from Delayed Rewards, Cambridge, 1989. <a href="http://www.cs.rhul.ac.uk/home/chrisw/thesis.html">[Thesis]</a>
</li>
</ul>
</li>
<li>Sarsa (On-policy TD algorithm):

<ul>
<li>G.A. Rummery, M. Niranjan, On-line Q-learning using connectionist systems, Technical Report, Cambridge Univ., 1994. <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;ved=0CDIQFjACahUKEwj2lMm5wZDIAhUHkg0KHa6kAVM&amp;url=ftp%3A%2F%2Fmi.eng.cam.ac.uk%2Fpub%2Freports%2Fauto-pdf%2Frummery_tr166.pdf&amp;usg=AFQjCNHz6IrgcaaO5lzC7t8oEIBY9epozg&amp;sig2=sa-emPme1m5Jav7YmaXsNQ&amp;cad=rja">[Report]</a>
</li>
<li>Richard S. Sutton, Generalization in Reinforcement Learning: Successful examples using sparse coding, NIPS, 1996. <a href="http://webdocs.cs.ualberta.ca/%7Esutton/papers/sutton-96.pdf">[Paper]</a>
</li>
</ul>
</li>
<li>R-Learning (learning of relative values)

<ul>
<li>Andrew Schwartz, A Reinforcement Learning Method for Maximizing Undiscounted Rewards, ICML, 1993. <a href="https://scholar.google.com/scholar?q=reinforcement+learning+method+for+maximizing+undiscounted+rewards&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart&amp;sa=X&amp;ved=0CBsQgQMwAGoVChMIho6p_MOQyAIVwh0eCh3XWAwM">[Paper-Google Scholar]</a>
</li>
</ul>
</li>
<li>Function Approximation methods (Least-Sqaure Temporal Difference, Least-Sqaure Policy Iteration)

<ul>
<li>Steven J. Bradtke, Andrew G. Barto, Linear Least-Squares Algorithms for Temporal Difference Learning, Machine Learning, 1996. <a href="http://www-anw.cs.umass.edu/pubs/1995_96/bradtke_b_ML96.pdf">[Paper]</a>
</li>
<li>Michail G. Lagoudakis, Ronald Parr, Model-Free Least Squares Policy Iteration, NIPS, 2001. <a href="http://www.cs.duke.edu/research/AI/LSPI/nips01.pdf">[Paper]</a> <a href="http://www.cs.duke.edu/research/AI/LSPI/">[Code]</a>
</li>
</ul>
</li>
<li>Policy Search (in application to Robotics)

<ul>
<li>Nate Kohl, Peter Stone, Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion, ICRA, 2004. <a href="http://www.cs.utexas.edu/%7Epstone/Papers/bib2html-links/icra04.pdf">[Paper]</a>
</li>
<li>Marc Deisenroth, Carl Rasmussen, PILCO: A Model-Based and Data-Efficient Approach to Policy Search, ICML, 2011. <a href="http://mlg.eng.cam.ac.uk/pub/pdf/DeiRas11.pdf">[Paper]</a>
</li>
<li>Jan Peters, Sethu Vijayakumar, Stefan Schaal, Natural Actor-Critic, ECML, 2005. <a href="https://homes.cs.washington.edu/%7Etodorov/courses/amath579/reading/NaturalActorCritic.pdf">[Paper]</a>
</li>
<li>Scott Kuindersma, Roderic Grupen, Andrew Barto, Learning Dynamic Arm Motions for Postural Recovery, Humanoids, 2011. <a href="http://www-all.cs.umass.edu/pubs/2011/kuindersma_g_b_11.pdf">[Paper]</a>
</li>
</ul>
</li>
<li>Hierarchical RL

<ul>
<li>Richard Sutton, Doina Precup, Satinder Singh, Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning, Artificial Intelligence, 1999. <a href="https://webdocs.cs.ualberta.ca/%7Esutton/papers/SPS-aij.pdf">[Paper]</a>
</li>
<li>George Konidaris, Andrew Barto, Building Portable Options: Skill Transfer in Reinforcement Learning, IJCAI, 2007. <a href="http://www-anw.cs.umass.edu/pubs/2007/konidaris_b_IJCAI07.pdf">[Paper]</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>

<h2>
<a id="applications" class="anchor" href="#applications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Applications</h2>

<h3>
<a id="game-playing" class="anchor" href="#game-playing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Game Playing</h3>

<ul>
<li>
<p>Traditional Games</p>

<ul>
<li>Backgammon - "TD-Gammon" game play using TD(λ) (ACM 1995) <a href="http://www.bkgm.com/articles/tesauro/tdl.html">[Paper]</a>
</li>
<li>Chess - "KnightCap" program using TD(λ)  <a href="http://arxiv.org/pdf/cs/9901002v1.pdf">[Paper-arXiv]</a>
</li>
<li>Chess - Giraffe: Using deep reinforcement learning to play chess <a href="http://arxiv.org/pdf/1509.01549v2.pdf">[Paper-arXiv]</a>
</li>
</ul>
</li>
<li>
<p>Computer Games </p>

<ul>
<li>Human-level Control through Deep Reinforcement Learning (Nature 2015) <a href="http://www.readcube.com/articles/10.1038%2Fnature14236?shared_access_token=Lo_2hFdW4MuqEcF3CVBZm9RgN0jAjWel9jnR3ZoTv0P5kedCCNjz3FJ2FhQCgXkApOr3ZSsJAldp-tw3IWgTseRnLpAc9xQq-vTA2Z5Ji9lg16_WvCy4SaOgpK5XXA6ecqo8d8J7l4EJsdjwai53GqKt-7JuioG0r3iV67MQIro74l6IxvmcVNKBgOwiMGi8U0izJStLpmQp6Vmi_8Lw_A%3D%3D">[Paper]</a> <a href="https://sites.google.com/a/deepmind.com/dqn/">[Code]</a> <a href="https://www.youtube.com/watch?v=iqXKQf2BOSE">[Video]</a>
</li>
<li>
<a href="https://github.com/SarvagyaVaish/FlappyBirdRL">Flappy Bird Reinforcement Learning</a> <a href="https://www.youtube.com/watch?v=xM62SpKAZHU">[Video]</a>
</li>
<li>MarI/O (learning to play Mario with evolutionary reinforcement learning using artificial neural networks) <a href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf">[Paper]</a><a href="https://www.youtube.com/watch?v=qv6UVOQ0F44">[Video]</a>
</li>
</ul>
</li>
</ul>

<h3>
<a id="robotics" class="anchor" href="#robotics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Robotics</h3>

<ul>
<li>Reinforcement Learning for Humanoid Robotics (ICHR 2003) <a href="http://www-clmc.usc.edu/publications/p/peters-ICHR2003.pdf">[Paper]</a>
</li>
<li>Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion (ICRA 2004) <a href="http://www.cs.utexas.edu/%7Epstone/Papers/bib2html-links/icra04.pdf">[Paper]</a>
</li>
<li>Robot Motor SKill Coordination with EM-based Reinforcement Learning (IROS 2010) <a href="http://kormushev.com/papers/Kormushev-IROS2010.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=W_gxLKSsSIE">[Video]</a>
</li>
<li>Generalized Model Learning for Reinforcement Learning on a Humanoid Robot (ICRA 2010) <a href="https://ccc.inaoep.mx/%7Emdprl/documentos/Hester_2010.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=mRpX9DFCdwI&amp;list=PL5nBAYUyJTrM48dViibyi68urttMlUv7e&amp;index=12">[Video]</a> </li>
<li>Autonomous Skill Acquisition on a Mobile Manipulator (AAAI 2011) <a href="https://www.youtube.com/watch?v=yUICAkSQTZY">[Paper]</a> <a href="https://www.youtube.com/watch?v=yUICAkSQTZY">[Video]</a>
</li>
<li>PILCO: A Model-Based and Data-Efficient Approach to Policy Search (ICML 2011) <a href="http://mlg.eng.cam.ac.uk/pub/pdf/DeiRas11.pdf">[Paper]</a>
</li>
<li>Incremental Semantically Grounded Learning from Demonstration (RSS 2013) <a href="http://people.cs.umass.edu/%7Esniekum/pubs/NiekumRSS2013.pdf">[Paper]</a>
</li>
<li>Efficient Reinforcement Learning for Robots using Informative Simulated Priors (ICRA 2015) <a href="http://markjcutler.com/papers/Cutler15_ICRA.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=kKClFx6l1HY">[Video]</a>
</li>
</ul>

<h3>
<a id="control" class="anchor" href="#control" aria-hidden="true"><span class="octicon octicon-link"></span></a>Control</h3>

<ul>
<li>An Application of Reinforcement Learning to Aerobatic Helicopter Flight (NIPS 2006) <a href="http://heli.stanford.edu/papers/nips06-aerobatichelicopter.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=VCdxqn0fcnE">[Video]</a>
</li>
<li>Autonomous helicopter control using Reinforcement Learning Policy Search Methods (ICRA 2011) <a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1082&amp;context=robotics">[Paper]</a>
</li>
</ul>

<h3>
<a id="operations-research" class="anchor" href="#operations-research" aria-hidden="true"><span class="octicon octicon-link"></span></a>Operations Research</h3>

<ul>
<li>Scaling Average-reward Reinforcement Learning for Product Delivery (AAAI 2004) <a href="http://web.engr.oregonstate.edu/%7Eproper/AAAI04SProper.pdf">[Paper]</a>
</li>
<li>Cross Channel Optimized Marketing by Reinforcement Learning (KDD 2004) <a href="http://www.research.ibm.com/people/n/nabe/kdd04AVAS.pdf">[Paper]</a>
</li>
</ul>

<h3>
<a id="human-computer-interaction" class="anchor" href="#human-computer-interaction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Human Computer Interaction</h3>

<ul>
<li>Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System (JAIR 2002) <a href="http://web.eecs.umich.edu/%7Ebaveja/Papers/RLDSjair.pdf">[Paper]</a>
</li>
</ul>

<h2>
<a id="tutorials--websites" class="anchor" href="#tutorials--websites" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tutorials / Websites</h2>

<ul>
<li>Mance Harmon and Stephanie Harmon, <a href="http://old.nbu.bg/cogs/events/2000/Readings/Petrov/rltutorial.pdf">Reinforcement Learning: A Tutorial</a>
</li>
<li><a href="http://webdocs.cs.ualberta.ca/%7Evanhasse/rl_algs/rl_algs.html">Short introduction to some Reinforcement Learning algorithms</a></li>
<li>C. Igel, M.A. Riedmiller, et al., Reinforcement Learning in a Nutshell, ESANN, 2007. <a href="http://image.diku.dk/igel/paper/RLiaN.pdf">[Paper]</a>
</li>
<li>UNSW - <a href="http://www.cse.unsw.edu.au/%7Ecs9417ml/RL1/index.html">Reinforcement Learning</a>

<ul>
<li>
<a href="http://www.cse.unsw.edu.au/%7Ecs9417ml/RL1/introduction.html">Introduction</a> </li>
<li><a href="http://www.cse.unsw.edu.au/%7Ecs9417ml/RL1/tdlearning.html">TD-Learning</a></li>
<li><a href="http://www.cse.unsw.edu.au/%7Ecs9417ml/RL1/algorithms.html">Q-Learning and SARSA</a></li>
<li>
<a href="http://www.cse.unsw.edu.au/%7Ecs9417ml/RL1/applet.html">Applet for "Cat and Mouse" Game</a> </li>
</ul>
</li>
<li><a href="http://wiki.ros.org/reinforcement_learning/Tutorials/Reinforcement%20Learning%20Tutorial">ROS Reinforcement Learning Tutorial</a></li>
<li><a href="http://cs.brown.edu/research/ai/pomdp/tutorial/index.html">POMDP for Dummies</a></li>
<li>Scholarpedia articles on:

<ul>
<li>
<a href="http://www.scholarpedia.org/article/Reinforcement_learning">Reinforcement Learning</a> </li>
<li><a href="http://www.scholarpedia.org/article/Temporal_difference_learning">Temporal Difference Learning</a></li>
</ul>
</li>
<li>Repository with useful <a href="http://busoniu.net/repository.php">MATLAB Software, presentations, and demo videos</a> </li>
<li><a href="http://liinwww.ira.uka.de/bibliography/Neural/reinforcement.learning.html">Bibliography on Reinforcement Learning</a></li>
</ul>

<h2>
<a id="online-demos" class="anchor" href="#online-demos" aria-hidden="true"><span class="octicon octicon-link"></span></a>Online Demos</h2>

<ul>
<li><a href="http://www.dcsc.tudelft.nl/%7Erobotics/media.html">Real-world demonstrations of Reinforcement Learning</a></li>
</ul>
        </article>
      </div>
    </div>
    <footer>
      <div class="owner">
      <p><a href="https://github.com/aikorea" class="avatar"><img src="https://avatars0.githubusercontent.com/u/13035374?v=3&amp;s=60" width="48" height="48"></a> <a href="https://github.com/aikorea">aikorea</a> maintains <a href="https://github.com/aikorea/awesome-rl">Awesome-rl</a></p>


      </div>
      <div class="creds">
        <small>This page generated using <a href="https://pages.github.com/">GitHub Pages</a><br>theme by <a href="https://twitter.com/jonrohan/">Jon Rohan</a></small>
      </div>
    </footer>
  </div>
  <div class="current-section">
    <a href="#top">Scroll to top</a>
    <a href="https://github.com/aikorea/awesome-rl/tarball/master" class="tar">tar</a><a href="https://github.com/aikorea/awesome-rl/zipball/master" class="zip">zip</a><a href="" class="code">source code</a>
    <p class="name"></p>
  </div>

            <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-67529920-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

</body>
</html>
